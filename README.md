# Writer-Identification_WLSR


![](https://github.com/KiM55/Writer-Identification-WLSR/blob/master/Image/fig1.jpg)

# Overview 
- [Citation](#citation)
- [Dependences](#dependences)
- [Line_Segmentation](#line_segmentation)
- [Feature_Extraction](#feature_extraction)
- [References](#references)
- [Citation](#citation)
- [Contact](#contact)


Codes of this repository are for papper entitled with ["Semi-Supervised Feature Learning for Improving Writer Identification"](https://www.sciencedirect.com/science/article/pii/S0020025519300283?via%3Dihub), which had been published on Information Sciences.





# Dependences 
- Matlab, Matconvnet, Opencv, NVIDIA GPU
- **(Note that I have included my Matconvnet in this repo, so you do not need to download it again. I has changed some codes comparing with the original version. For example, one of the difference is in `/matlab/+dagnn/@DagNN/initParams.m`. If one layer has params, I will not initialize it again, especially for pretrained model.)**

	You just need to uncomment and modify some lines in `compile.m` and run it in Matlab. Try it~
	(The code does not support cudnn 6.0. You may just turn off the Enablecudnn or try cudnn5.1)

	If you fail in compilation, you may refer to http://www.vlfeat.org/matconvnet/install/

# Line_Segmentation
At first, you segment the document to lines with statistical line segmentation. You can refer to guideline (https://github.com/KiM55/DLS-CNN/).

# Feature_Extraction 

### Train
1. Make a dir called `data` by typing `mkdir ./data`.

2. Download [ResNet-50 model](http://www.vlfeat.org/matconvnet/models/imagenet-resnet-50-dag.mat) pretrained on Imagenet. Put it in the `data` dir. 

3. Add your original dataset path and extra dataset path into `prepare_data.m` and `prepare_extra_data.m` and run it. Make sure the code outputs the right image path.

4.  Run `train_id_net_res_market_wlsr.m` (Single) or `resnet52_2stream_wlsr_fc_identify_solely.m` (2-Stream) for training the proposed method.

### Test

Run `test/feature_extraction.m` to extract the features of images in the gallery and query set. They will store in a .mat file. Then you can use it to do evaluation.

### Evaluation
Run `evaluation/evaluation.m` for evaluation.


# References
- \[1\] 'Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro' by Zhedong Zheng et. al, [paper](https://arxiv.org/abs/1701.07717), [code](https://github.com/layumi/Person-reID_GAN)
- \[2\] 'A Robust Off-line Writer Identification Method' by Shiming Chen  et. al, [paper](http://kns.cnki.net/KCMS/detail/11.2109.TP.20181113.1155.001.html), [code](https://github.com/KiM55/DLS-CNN)


# Citation
If this work is helpful for you, please cite my paper.

```
@article{Chen2019Semi,  
  title={Semi-Supervised Feature Learning for Improving Writer Identification},    
  author={Chen, Shiming and Wang, Yisong and Lin, Chin-Teng Lin and Ding, Weiping and Cao, Zehong},    
  journal={Information Sciences}, 
  volume={482},
  pages={156-170},
  year={2019}    
}
```

# Contact
If you run into any problems with these codes, please submit a bug report on the Github site of the project. For another inquries please contact with me: gchenshiming@gmail.com or g_shmchen@163.com




